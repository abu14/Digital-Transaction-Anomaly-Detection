{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.append(os.path.abspath('../scripts/model'))\n",
    "sys.path.append(os.path.abspath('../scripts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_analysis_and_preprocessing as dap\n",
    "import model_training_for_fraud_data as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 23:33:33,047 - root - INFO - loading the data\n"
     ]
    }
   ],
   "source": [
    "df_fraud = dap.load_data('../data/final_fraud_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature and Trget Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 23:33:34,814 - root - INFO - feature and target\n",
      "2024-10-28 23:33:34,819 - root - INFO - fraud data target separation\n"
     ]
    }
   ],
   "source": [
    "x_fraud_data,y_fraud_data = mt.feature_and_target_separation(df_fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 23:33:34,881 - root - INFO - spliting the data to evaluate the model's performance on unseen data\n",
      "2024-10-28 23:33:34,886 - root - INFO - spliting the fraud data into train and test\n"
     ]
    }
   ],
   "source": [
    "X_train_fraud,X_test_fraud,y_train_fraud,y_test_fraud = mt.train_test_splite(x_fraud_data,y_fraud_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training And Evaluation using the Fraud Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 23:33:35,080 - root - INFO - Training the model and evaluating their performance\n",
      "2024-10-28 23:33:35,084 - root - INFO - Defining the preprocessing steps\n",
      "2024-10-28 23:33:36,723 - root - INFO - Defining the models\n",
      "2024-10-28 23:33:36,727 - root - INFO - Training and evaluating each model\n",
      "2024-10-28 23:33:36,731 - root - INFO - Training Logistic Regression\n",
      "c:\\Users\\bekib\\Desktop\\10ACADAMY\\WEEK-EIGHT-AND-NINE\\week-8$9\\.week-8_9\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-10-28 23:33:39,187 - root - INFO - Training Decision Tree\n",
      "2024-10-28 23:33:43,827 - root - INFO - Training Random Forest\n",
      "2024-10-28 23:34:23,703 - root - INFO - Training Gradient Boosting\n",
      "2024-10-28 23:34:56,459 - root - INFO - Training Multi-Layer Perception\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall  F1 Score   ROC AUC\n",
      "Logistic Regression     0.907355   0.000000  0.000000  0.000000  0.576829\n",
      "Decision Tree           0.896800   0.454700  0.571786  0.506565  0.750622\n",
      "Random Forest           0.955299   0.945846  0.548929  0.694689  0.772224\n",
      "Gradient Boosting       0.907653   1.000000  0.003214  0.006408  0.742549\n",
      "Multi-Layer Perception  0.912451   0.564167  0.241786  0.338500  0.758505\n"
     ]
    }
   ],
   "source": [
    "model = mt.model_Traingin_and_Evaluation(X_train_fraud,X_test_fraud,y_train_fraud,y_test_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic_Regression saved at ../fraud/models\\Logistic_Regression.pkl\n",
      "Decision_Tree saved at ../fraud/models\\Decision_Tree.pkl\n",
      "Random_Forest saved at ../fraud/models\\Random_Forest.pkl\n",
      "Gradient_Boosting saved at ../fraud/models\\Gradient_Boosting.pkl\n",
      "MLP_Classifier saved at ../fraud/models\\MLP_Classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Define the names of the models for saving\n",
    "model_names = [\n",
    "    \"Logistic_Regression\",\n",
    "    \"Decision_Tree\",\n",
    "    \"Random_Forest\",\n",
    "    \"Gradient_Boosting\",\n",
    "    \"MLP_Classifier\"\n",
    "]\n",
    "\n",
    "# Directory to save the models\n",
    "model_dir = \"../fraud/models\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Save each model as a .pkl file using joblib\n",
    "for m, name in zip(model, model_names):\n",
    "    model_path = os.path.join(model_dir, f\"{name}.pkl\")\n",
    "    joblib.dump(m, model_path)  # Using joblib's dump function to save the model\n",
    "    print(f\"{name} saved at {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".week-8_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
